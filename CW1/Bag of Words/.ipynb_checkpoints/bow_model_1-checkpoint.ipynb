{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train_data.txt')\n",
    "data = []\n",
    "for line in file:\n",
    "    sitem = line.split(\" \",1)\n",
    "    data.append((sitem[1].split(),sitem[0]))\n",
    "#print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test.txt')\n",
    "test_data = []\n",
    "for line in file:\n",
    "    sitem = line.split(\" \",1)\n",
    "    test_data.append((sitem[1].split(),sitem[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "word_to_ix = {'<unknown_word>': 0}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "NUM_LABELS = 50\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "#print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.small.txt','r')as f:\n",
    "    glovedata =[line.strip() for line in f]\n",
    "    index2word=[i.split()[0] for i in glovedata]\n",
    "    getWordvector={i.split()[0]:list(map(float,i.split()[1:])) for i in glovedata}\n",
    "#print((getWordvector.get('donate')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allTag.txt','r') as r_tag:\n",
    "    result=r_tag.read().split()\n",
    "    tagvocab=list(set(result))\n",
    "    tagvocab.sort(key=result.index)\n",
    "    label_to_ix={result:i for i,result in enumerate(tagvocab)}\n",
    "    ix_to_label={i:result for i,result in enumerate(tagvocab)}\n",
    "#print(label_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_each_label = torch.zeros(50)\n",
    "\n",
    "for i in range(0,500):\n",
    "    ix_label = label_to_ix.get(test_data[i][1])\n",
    "    count_of_each_label[ix_label] += 1\n",
    "\n",
    "#print(count_of_each_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=300\n",
    "weight = torch.zeros(VOCAB_SIZE,embedding_dim)\n",
    "for i in range(len(index2word)):\n",
    "    try:\n",
    "        index=word_to_ix[index2word[i]]\n",
    "    except:\n",
    "        continue\n",
    "    weight[index,:]=torch.tensor(getWordvector[index2word[i]])\n",
    "    \n",
    "stopwords= ['a','up','did','to','if','in','was','the','nor','off','that','or','be','too','very']\n",
    "for items in stopwords:\n",
    "    idx_stopword = word_to_ix.get(items)\n",
    "    weight[idx_stopword,:]=torch.zeros(1,300)\n",
    "#print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BoWClassifier(nn.Module):  \n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(300)\n",
    "    for word in sentence:\n",
    "        idx = word_to_ix[word]\n",
    "        k = weight[idx,:]\n",
    "        vec = vec + k.clone().detach()\n",
    "    final_sent_vec = vec/len(sentence)\n",
    "    return final_sent_vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "VEC_SIZE = 300\n",
    "model = BoWClassifier(NUM_LABELS, VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.parameters():\n",
    " #   print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate before training is :0.044\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        target = make_target(label, label_to_ix)\n",
    "        problist = log_probs.numpy().tolist()\n",
    "        index_max= problist[0].index(max(problist[0]))\n",
    "        if index_max == label_to_ix[label]:\n",
    "            correct = correct+1\n",
    "        #print(instance)\n",
    "        #print(\"The predict label is :\" + ix_to_label[index_max]+\"   The real label is \"+ label)\n",
    "correct_rate = correct/500\n",
    "print(\"The accuracy rate before training is :\" + str(correct_rate))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(15):\n",
    "    for instance, label in data:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        target = make_target(label, label_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate after training is :0.774\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "correct = 0\n",
    "correct_label_count= torch.zeros(50)\n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        target = make_target(label, label_to_ix)\n",
    "        problist = log_probs.numpy().tolist()\n",
    "        index_max= problist[0].index(max(problist[0]))\n",
    "        if index_max == label_to_ix[label]:\n",
    "            correct = correct+1\n",
    "            correct_label_count[index_max] += 1\n",
    "        #print(instance)\n",
    "        #print(\"The predict label is :\" + ix_to_label[index_max]+\"   The real label is \"+ label)\n",
    "        \n",
    "#print(correct_label_count)        \n",
    "correct_rate = correct/500\n",
    "print(\"The accuracy rate after training is :\" + str(correct_rate))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_each_label= torch.div(correct_label_count,count_of_each_label)\n",
    "#print(accuracy_of_each_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
